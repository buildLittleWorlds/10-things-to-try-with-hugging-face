{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 6. Zero-Shot Classification\n",
    "\n",
    "**Estimated Time**: ~2 hours\n",
    "\n",
    "**Prerequisites**: Notebooks 1-5 (understanding of model flexibility from text generation, basic NLP concepts)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. **Understand** how zero-shot classification works without task-specific training\n",
    "2. **Explain** how Natural Language Inference (NLI) enables flexible classification\n",
    "3. **Design** effective label sets for different classification tasks\n",
    "4. **Handle** multi-label classification scenarios\n",
    "5. **Build** a custom content tagger for real-world use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run this cell first. If you completed previous notebooks, you already have the core packages ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "from transformers import pipeline\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Conceptual Foundation\n",
    "\n",
    "## What is Zero-Shot Classification?\n",
    "\n",
    "**In plain English**: Zero-shot classification lets a model categorize text into categories it was never explicitly trained on. You just tell it what categories exist, and it figures out which one fits.\n",
    "\n",
    "**Technical definition**: Zero-shot classification uses a model trained on Natural Language Inference (NLI) to determine if a text \"entails\" (implies) a given label hypothesis, without requiring task-specific fine-tuning.\n",
    "\n",
    "### Why \"Zero-Shot\"?\n",
    "\n",
    "```\n",
    "TRADITIONAL CLASSIFICATION:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Step 1: Collect thousands of labeled examples              â”‚\n",
    "â”‚          \"This is great!\" â†’ positive                        â”‚\n",
    "â”‚          \"I hate this\" â†’ negative                           â”‚\n",
    "â”‚          ... (thousands more) ...                           â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚  Step 2: Train a model specifically for this task           â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚  Step 3: Model can ONLY classify into [positive, negative]  â”‚\n",
    "â”‚          Want new categories? Start over at Step 1!         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "ZERO-SHOT CLASSIFICATION:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Step 1: Load pre-trained model (already done!)             â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚  Step 2: Give it ANY labels you want                        â”‚\n",
    "â”‚          [\"positive\", \"negative\", \"neutral\"]                â”‚\n",
    "â”‚          [\"sports\", \"politics\", \"entertainment\"]            â”‚\n",
    "â”‚          [\"urgent\", \"normal\", \"spam\"]                       â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚  Step 3: Classify! Change labels anytime!                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**\"Zero-shot\"** = zero training examples needed for your specific task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "### How It Works: Natural Language Inference (NLI)\n",
    "\n",
    "The secret is **NLI** - a task where models learn to determine relationships between sentences:\n",
    "\n",
    "```\n",
    "NLI TASK:\n",
    "Given a PREMISE and a HYPOTHESIS, determine their relationship:\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Premise:    \"A man is playing guitar on stage.\"           â”‚\n",
    "â”‚  Hypothesis: \"A musician is performing.\"                   â”‚\n",
    "â”‚  Relationship: ENTAILMENT âœ“ (premise implies hypothesis)   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Premise:    \"A man is playing guitar on stage.\"           â”‚\n",
    "â”‚  Hypothesis: \"The stage is empty.\"                         â”‚\n",
    "â”‚  Relationship: CONTRADICTION âœ— (premise contradicts hyp.)  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Premise:    \"A man is playing guitar on stage.\"           â”‚\n",
    "â”‚  Hypothesis: \"The guitar is red.\"                          â”‚\n",
    "â”‚  Relationship: NEUTRAL â—‹ (can't tell from premise)         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Turning NLI into Classification\n",
    "\n",
    "```\n",
    "ZERO-SHOT CLASSIFICATION TRICK:\n",
    "\n",
    "Text to classify: \"Apple announces new iPhone with better camera\"\n",
    "Labels: [\"technology\", \"sports\", \"politics\"]\n",
    "\n",
    "Convert to NLI format:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Premise: \"Apple announces new iPhone with better camera\"     â”‚\n",
    "â”‚                                                                â”‚\n",
    "â”‚  Test each label as hypothesis:                                â”‚\n",
    "â”‚                                                                â”‚\n",
    "â”‚  Hypothesis: \"This text is about technology.\"                 â”‚\n",
    "â”‚  â†’ ENTAILMENT score: 0.92 âœ“ HIGH                              â”‚\n",
    "â”‚                                                                â”‚\n",
    "â”‚  Hypothesis: \"This text is about sports.\"                     â”‚\n",
    "â”‚  â†’ ENTAILMENT score: 0.03 âœ— LOW                               â”‚\n",
    "â”‚                                                                â”‚\n",
    "â”‚  Hypothesis: \"This text is about politics.\"                   â”‚\n",
    "â”‚  â†’ ENTAILMENT score: 0.05 âœ— LOW                               â”‚\n",
    "â”‚                                                                â”‚\n",
    "â”‚  Result: \"technology\" wins!                                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### Connection to Previous Notebooks\n",
    "\n",
    "| Notebook | Model Flexibility | Training Required |\n",
    "|----------|-------------------|------------------|\n",
    "| 1-4 (MLM, NER, QA, Summarization) | Fixed tasks | Task-specific training |\n",
    "| 5 (Text Generation) | Flexible prompts | No fine-tuning needed |\n",
    "| **6 (Zero-Shot Classification)** | **Any labels** | **No training needed** |\n",
    "\n",
    "Like text generation, zero-shot classification demonstrates the flexibility of modern language models - they can perform tasks they weren't explicitly trained for!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "### The Hypothesis Template\n",
    "\n",
    "The model converts labels into hypotheses using a template:\n",
    "\n",
    "```\n",
    "Default template: \"This example is {label}.\"\n",
    "\n",
    "Label \"technology\" â†’ \"This example is technology.\"\n",
    "Label \"sports\"     â†’ \"This example is sports.\"\n",
    "\n",
    "Custom templates can improve accuracy:\n",
    "\"This text is about {label}.\"      â†’ Better for topics\n",
    "\"The sentiment is {label}.\"        â†’ Better for sentiment\n",
    "\"This email is {label}.\"           â†’ Better for email classification\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### Real-World Applications\n",
    "\n",
    "Zero-shot classification is powerful for:\n",
    "\n",
    "- **Content Moderation**: Classify user content into categories (safe, nsfw, spam)\n",
    "- **Customer Support**: Route tickets to departments without pre-labeling\n",
    "- **News Categorization**: Tag articles with topics dynamically\n",
    "- **Sentiment Analysis**: Classify into any sentiment scale you define\n",
    "- **Intent Detection**: Understand user intent in chatbots\n",
    "- **Rapid Prototyping**: Test classification ideas without collecting labeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Key Terminology\n",
    "\n",
    "| Term | Definition |\n",
    "|------|------------|\n",
    "| **Zero-shot** | Classification without task-specific training examples |\n",
    "| **NLI** | Natural Language Inference - determining logical relationships |\n",
    "| **Entailment** | When one statement logically implies another |\n",
    "| **Hypothesis Template** | Pattern for converting labels into test sentences |\n",
    "| **Multi-label** | When text can belong to multiple categories |\n",
    "| **Candidate Labels** | The possible categories for classification |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### Check Your Understanding\n",
    "\n",
    "Before moving on, try to answer these questions (answers at the end):\n",
    "\n",
    "1. Why is it called \"zero-shot\" classification?\n",
    "   - A) Because it takes zero seconds to run\n",
    "   - B) Because it needs zero task-specific training examples\n",
    "   - C) Because it has zero accuracy\n",
    "\n",
    "2. What NLI relationship does zero-shot classification look for?\n",
    "   - A) Contradiction\n",
    "   - B) Entailment\n",
    "   - C) Neutral\n",
    "\n",
    "3. What is the purpose of the hypothesis template?\n",
    "   - A) To generate new text\n",
    "   - B) To convert labels into testable sentences\n",
    "   - C) To train the model\n",
    "\n",
    "4. Which is a valid use case for zero-shot classification?\n",
    "   - A) Classifying text into categories you just invented\n",
    "   - B) Generating text continuations\n",
    "   - C) Translating between languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Basic Implementation\n",
    "\n",
    "## Your First Zero-Shot Classification\n",
    "\n",
    "Let's classify some text into categories we define on the fly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "# Text to classify\n",
    "text = \"The new smartphone features a revolutionary camera system with 200MP resolution.\"\n",
    "\n",
    "# Define candidate labels - you can use ANY labels!\n",
    "candidate_labels = [\"technology\", \"sports\", \"politics\", \"entertainment\"]\n",
    "\n",
    "# Classify\n",
    "result = classifier(text, candidate_labels)\n",
    "\n",
    "print(\"Zero-Shot Classification Result:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Text: \\\"{text}\\\"\")\n",
    "print(f\"\\nScores:\")\n",
    "for label, score in zip(result['labels'], result['scores']):\n",
    "    bar = '*' * int(score * 40)\n",
    "    print(f\"  {label:15s} {score:.1%} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "### Understanding the Output\n",
    "\n",
    "The pipeline returns a dictionary with:\n",
    "- `sequence`: The input text\n",
    "- `labels`: Labels sorted by score (highest first)\n",
    "- `scores`: Probability scores for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the full output structure\n",
    "print(\"Full Output Structure:\")\n",
    "print(\"=\"*50)\n",
    "for key, value in result.items():\n",
    "    if key == 'sequence':\n",
    "        print(f\"{key}: \\\"{value[:50]}...\\\"\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "### Trying Different Label Sets\n",
    "\n",
    "The magic of zero-shot: just change the labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same text, different label sets\n",
    "text = \"I can't believe how terrible the service was at this restaurant. Never going back!\"\n",
    "\n",
    "label_sets = {\n",
    "    \"Sentiment\": [\"positive\", \"negative\", \"neutral\"],\n",
    "    \"Emotion\": [\"anger\", \"joy\", \"sadness\", \"surprise\"],\n",
    "    \"Category\": [\"complaint\", \"compliment\", \"question\", \"suggestion\"],\n",
    "    \"Urgency\": [\"urgent\", \"normal\", \"low priority\"],\n",
    "}\n",
    "\n",
    "print(f\"Text: \\\"{text}\\\"\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for set_name, labels in label_sets.items():\n",
    "    result = classifier(text, labels)\n",
    "    top_label = result['labels'][0]\n",
    "    top_score = result['scores'][0]\n",
    "    \n",
    "    print(f\"\\n[{set_name}]\")\n",
    "    print(f\"  Labels: {labels}\")\n",
    "    print(f\"  Prediction: {top_label} ({top_score:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "### Classifying Multiple Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify multiple texts at once\n",
    "texts = [\n",
    "    \"The Lakers dominated the fourth quarter to secure the championship.\",\n",
    "    \"Congress passes new legislation on climate change initiatives.\",\n",
    "    \"The movie broke box office records in its opening weekend.\",\n",
    "    \"Scientists discover new exoplanet in habitable zone.\",\n",
    "    \"Stock market reaches all-time high amid economic optimism.\",\n",
    "]\n",
    "\n",
    "labels = [\"sports\", \"politics\", \"entertainment\", \"science\", \"business\"]\n",
    "\n",
    "print(\"Multi-Text Classification:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for text in texts:\n",
    "    result = classifier(text, labels)\n",
    "    top = result['labels'][0]\n",
    "    score = result['scores'][0]\n",
    "    \n",
    "    print(f\"\\n\\\"{text[:60]}...\\\"\")\n",
    "    print(f\"  â†’ {top} ({score:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: News Article Classifier (Guided)\n",
    "\n",
    "**Difficulty**: Basic | **Time**: 10-15 minutes\n",
    "\n",
    "**Your task**: Build a news article classifier that can categorize headlines into different topics.\n",
    "\n",
    "### Step 1: Create a news classifier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_news(headline, categories=None):\n",
    "    \"\"\"\n",
    "    Classify a news headline into categories.\n",
    "    \n",
    "    Args:\n",
    "        headline: The news headline text\n",
    "        categories: List of possible categories (optional)\n",
    "        \n",
    "    Returns:\n",
    "        dict with top category and all scores\n",
    "    \"\"\"\n",
    "    if categories is None:\n",
    "        categories = [\n",
    "            \"world news\", \n",
    "            \"business\", \n",
    "            \"technology\", \n",
    "            \"sports\", \n",
    "            \"entertainment\",\n",
    "            \"science\",\n",
    "            \"health\"\n",
    "        ]\n",
    "    \n",
    "    result = classifier(headline, categories)\n",
    "    \n",
    "    return {\n",
    "        'headline': headline,\n",
    "        'top_category': result['labels'][0],\n",
    "        'confidence': result['scores'][0],\n",
    "        'all_scores': dict(zip(result['labels'], result['scores'])),\n",
    "    }\n",
    "\n",
    "\n",
    "# Test with sample headlines\n",
    "test_headlines = [\n",
    "    \"Tesla Stock Surges 15% After Record Q4 Deliveries\",\n",
    "    \"WHO Declares End of Global Health Emergency\",\n",
    "    \"SpaceX Successfully Launches 50 More Starlink Satellites\",\n",
    "    \"Olympic Committee Announces New Host City for 2036 Games\",\n",
    "]\n",
    "\n",
    "print(\"News Article Classification:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for headline in test_headlines:\n",
    "    result = classify_news(headline)\n",
    "    print(f\"\\n\\\"{result['headline']}\\\"\")\n",
    "    print(f\"  Category: {result['top_category']} ({result['confidence']:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "### Step 2: Show full score breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of one headline\n",
    "headline = \"Major Tech Companies Report Mixed Earnings Amid AI Investment Surge\"\n",
    "result = classify_news(headline)\n",
    "\n",
    "print(f\"Detailed Analysis: \\\"{headline}\\\"\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sort by score for display\n",
    "sorted_scores = sorted(result['all_scores'].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for category, score in sorted_scores:\n",
    "    bar = '*' * int(score * 40)\n",
    "    marker = \" â† TOP\" if category == result['top_category'] else \"\"\n",
    "    print(f\"  {category:15s} {score:6.1%} {bar}{marker}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "### Step 3: Try your own headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Write your own headlines and classify them\n",
    "\n",
    "my_headline = \"Your headline here\"\n",
    "\n",
    "# Uncomment to run:\n",
    "# result = classify_news(my_headline)\n",
    "# print(f\"Category: {result['top_category']} ({result['confidence']:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Intermediate Exploration\n",
    "\n",
    "## Multi-Label Classification\n",
    "\n",
    "Sometimes text belongs to multiple categories. Zero-shot handles this too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-label example: a text can belong to multiple categories\n",
    "text = \"The tech billionaire's foundation announced a $500 million donation to climate research.\"\n",
    "\n",
    "labels = [\"technology\", \"business\", \"philanthropy\", \"environment\", \"politics\"]\n",
    "\n",
    "# Single-label (default): labels must sum to 1\n",
    "single_result = classifier(text, labels, multi_label=False)\n",
    "\n",
    "# Multi-label: each label is scored independently\n",
    "multi_result = classifier(text, labels, multi_label=True)\n",
    "\n",
    "print(f\"Text: \\\"{text}\\\"\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[SINGLE-LABEL] (scores sum to ~1)\")\n",
    "for label, score in zip(single_result['labels'], single_result['scores']):\n",
    "    bar = '*' * int(score * 30)\n",
    "    print(f\"  {label:15s} {score:6.1%} {bar}\")\n",
    "print(f\"  Sum: {sum(single_result['scores']):.2f}\")\n",
    "\n",
    "print(\"\\n[MULTI-LABEL] (independent scores)\")\n",
    "for label, score in zip(multi_result['labels'], multi_result['scores']):\n",
    "    bar = '*' * int(score * 30)\n",
    "    applicable = \" â† APPLIES\" if score > 0.5 else \"\"\n",
    "    print(f\"  {label:15s} {score:6.1%} {bar}{applicable}\")\n",
    "print(f\"  Sum: {sum(multi_result['scores']):.2f} (can be >1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "### When to Use Multi-Label\n",
    "\n",
    "| Scenario | Use | Example |\n",
    "|----------|-----|--------|\n",
    "| Mutually exclusive categories | `multi_label=False` | Sentiment: positive/negative |\n",
    "| Overlapping categories | `multi_label=True` | Article topics: tech + business |\n",
    "| Tag assignment | `multi_label=True` | Social media hashtag suggestions |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-label for content tagging\n",
    "post = \"\"\"\n",
    "Just finished my morning run along the beach. The sunrise was incredible! \n",
    "Stopped for a healthy smoothie afterward. Feeling energized for the day. \n",
    "#mondaymotivation\n",
    "\"\"\"\n",
    "\n",
    "tags = [\"fitness\", \"nature\", \"food\", \"travel\", \"lifestyle\", \"motivation\"]\n",
    "\n",
    "result = classifier(post, tags, multi_label=True)\n",
    "\n",
    "print(\"Content Tagging (Multi-Label):\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Post: {post.strip()[:80]}...\")\n",
    "print(\"\\nSuggested Tags:\")\n",
    "\n",
    "# Show tags above threshold\n",
    "threshold = 0.3\n",
    "for label, score in zip(result['labels'], result['scores']):\n",
    "    if score > threshold:\n",
    "        print(f\"  #{label} ({score:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "### Label Phrasing Matters\n",
    "\n",
    "The way you phrase labels significantly affects results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label phrasing comparison\n",
    "text = \"I waited 45 minutes for my food and it arrived cold.\"\n",
    "\n",
    "label_variations = {\n",
    "    \"Simple\": [\"positive\", \"negative\"],\n",
    "    \"Descriptive\": [\"customer is satisfied\", \"customer is dissatisfied\"],\n",
    "    \"Emotional\": [\"happy experience\", \"frustrating experience\"],\n",
    "    \"Action-oriented\": [\"would recommend\", \"would not recommend\"],\n",
    "}\n",
    "\n",
    "print(f\"Text: \\\"{text}\\\"\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for style, labels in label_variations.items():\n",
    "    result = classifier(text, labels)\n",
    "    print(f\"\\n[{style}]\")\n",
    "    for label, score in zip(result['labels'], result['scores']):\n",
    "        bar = '*' * int(score * 30)\n",
    "        print(f\"  {label:25s} {score:.1%} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "### Using Hypothesis Templates\n",
    "\n",
    "You can customize how labels are converted to hypotheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom hypothesis templates\n",
    "text = \"Breaking: Earthquake magnitude 6.5 strikes coastal region, tsunami warning issued.\"\n",
    "\n",
    "labels = [\"natural disaster\", \"crime\", \"politics\", \"sports\"]\n",
    "\n",
    "# Default template\n",
    "result_default = classifier(text, labels)\n",
    "\n",
    "# Custom template with hypothesis_template parameter\n",
    "result_custom = classifier(\n",
    "    text, \n",
    "    labels,\n",
    "    hypothesis_template=\"This news article is about {}.\"\n",
    ")\n",
    "\n",
    "print(f\"Text: \\\"{text}\\\"\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[Default Template]\")\n",
    "for label, score in zip(result_default['labels'][:3], result_default['scores'][:3]):\n",
    "    print(f\"  {label:20s} {score:.1%}\")\n",
    "\n",
    "print(\"\\n[Custom Template: 'This news article is about {}.']\")\n",
    "for label, score in zip(result_custom['labels'][:3], result_custom['scores'][:3]):\n",
    "    print(f\"  {label:20s} {score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Multi-Label Scenario (Semi-guided)\n",
    "\n",
    "**Difficulty**: Intermediate | **Time**: 15-20 minutes\n",
    "\n",
    "**Your task**: Build a function that assigns multiple relevant tags to content and filters by a confidence threshold.\n",
    "\n",
    "**Hints**:\n",
    "1. Use `multi_label=True` for independent scoring\n",
    "2. Filter results by a confidence threshold\n",
    "3. Return tags sorted by relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "def auto_tag_content(text, available_tags, threshold=0.4, max_tags=5):\n",
    "    \"\"\"\n",
    "    Automatically assign relevant tags to content.\n",
    "    \n",
    "    Args:\n",
    "        text: The content to tag\n",
    "        available_tags: List of possible tags\n",
    "        threshold: Minimum confidence to include a tag\n",
    "        max_tags: Maximum number of tags to return\n",
    "        \n",
    "    Returns:\n",
    "        dict with selected tags and all scores\n",
    "    \"\"\"\n",
    "    # Classify with multi-label mode\n",
    "    result = classifier(text, available_tags, multi_label=True)\n",
    "    \n",
    "    # Filter by threshold and limit\n",
    "    selected_tags = []\n",
    "    for label, score in zip(result['labels'], result['scores']):\n",
    "        if score >= threshold and len(selected_tags) < max_tags:\n",
    "            selected_tags.append({'tag': label, 'confidence': score})\n",
    "    \n",
    "    return {\n",
    "        'text_preview': text[:100] + '...' if len(text) > 100 else text,\n",
    "        'selected_tags': selected_tags,\n",
    "        'all_scores': dict(zip(result['labels'], result['scores'])),\n",
    "    }\n",
    "\n",
    "\n",
    "# Test with various content\n",
    "test_contents = [\n",
    "    {\n",
    "        'text': \"\"\"Just launched my new app! It uses AI to help people learn \n",
    "                   languages through conversation practice. Available on iOS and Android.\"\"\",\n",
    "        'tags': [\"technology\", \"education\", \"mobile apps\", \"artificial intelligence\", \n",
    "                 \"entrepreneurship\", \"marketing\", \"social media\"]\n",
    "    },\n",
    "    {\n",
    "        'text': \"\"\"Recipe: Healthy quinoa bowl with roasted vegetables and tahini dressing. \n",
    "                   Perfect for meal prep! High in protein and takes only 30 minutes.\"\"\",\n",
    "        'tags': [\"food\", \"health\", \"recipes\", \"vegetarian\", \"meal prep\", \n",
    "                 \"quick meals\", \"nutrition\"]\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"Auto-Tagging Content:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for content in test_contents:\n",
    "    result = auto_tag_content(content['text'], content['tags'], threshold=0.35)\n",
    "    \n",
    "    print(f\"\\nContent: \\\"{result['text_preview']}\\\"\")\n",
    "    print(\"\\nSelected Tags:\")\n",
    "    for tag_info in result['selected_tags']:\n",
    "        print(f\"  #{tag_info['tag']} ({tag_info['confidence']:.1%})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all scores for one piece of content\n",
    "content = test_contents[0]\n",
    "result = auto_tag_content(content['text'], content['tags'], threshold=0.3)\n",
    "\n",
    "print(\"Full Score Breakdown:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sorted_scores = sorted(result['all_scores'].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for tag, score in sorted_scores:\n",
    "    bar = '*' * int(score * 40)\n",
    "    selected = \" [SELECTED]\" if score >= 0.3 else \"\"\n",
    "    print(f\"  {tag:25s} {score:6.1%} {bar}{selected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-35",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Advanced Topics\n",
    "\n",
    "## Comparing Different Models\n",
    "\n",
    "Different zero-shot models have different strengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default model\n",
    "print(\"Default zero-shot model:\")\n",
    "print(f\"  {classifier.model.name_or_path}\")\n",
    "\n",
    "# You can load different models\n",
    "# Popular options:\n",
    "# - facebook/bart-large-mnli (default, good all-around)\n",
    "# - MoritzLaworski/DeBERTa-v3-large-mnli-fever-anli-ling-wanli (higher accuracy)\n",
    "# - cross-encoder/nli-deberta-v3-base (faster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37",
   "metadata": {},
   "source": [
    "### Label Design Best Practices\n",
    "\n",
    "The quality of labels significantly affects results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label design examples\n",
    "email_text = \"\"\"\n",
    "Hi Team,\n",
    "\n",
    "The server is down and customers can't access their accounts. \n",
    "We need to fix this immediately - it's affecting thousands of users.\n",
    "\n",
    "Please escalate to the on-call engineer ASAP.\n",
    "\n",
    "Thanks,\n",
    "Support Team\n",
    "\"\"\"\n",
    "\n",
    "# Poor labels: too vague or overlapping\n",
    "poor_labels = [\"important\", \"email\", \"message\", \"text\"]\n",
    "\n",
    "# Good labels: specific and distinct\n",
    "good_labels = [\"urgent technical issue\", \"meeting request\", \"general inquiry\", \"spam\"]\n",
    "\n",
    "# Better labels: action-oriented\n",
    "best_labels = [\"requires immediate action\", \"can wait until tomorrow\", \"informational only\", \"no response needed\"]\n",
    "\n",
    "print(\"Label Design Comparison:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for label_type, labels in [(\"Poor\", poor_labels), (\"Good\", good_labels), (\"Best\", best_labels)]:\n",
    "    result = classifier(email_text, labels)\n",
    "    print(f\"\\n[{label_type} Labels]\")\n",
    "    print(f\"  Labels: {labels}\")\n",
    "    print(f\"  Top: {result['labels'][0]} ({result['scores'][0]:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-39",
   "metadata": {},
   "source": [
    "### Label Design Guidelines\n",
    "\n",
    "| Guideline | Bad Example | Good Example |\n",
    "|-----------|-------------|-------------|\n",
    "| Be specific | \"good\", \"bad\" | \"positive review\", \"negative review\" |\n",
    "| Avoid overlap | \"urgent\", \"important\" | \"urgent action needed\", \"routine matter\" |\n",
    "| Use natural language | \"cat1\", \"cat2\" | \"customer complaint\", \"product inquiry\" |\n",
    "| Match the domain | \"happy\", \"sad\" (for business) | \"satisfied customer\", \"dissatisfied customer\" |\n",
    "| Be exhaustive | 2 labels for complex tasks | Cover all possible categories |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "### Handling Edge Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge case: Ambiguous text\n",
    "ambiguous_texts = [\n",
    "    \"It was okay.\",  # Neutral/unclear sentiment\n",
    "    \"Apple.\",  # Missing context\n",
    "    \"ðŸŽ‰ðŸŽŠðŸ¥³\",  # Only emojis\n",
    "    \"The bank was steep.\",  # Word sense ambiguity\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "print(\"Handling Ambiguous Text:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for text in ambiguous_texts:\n",
    "    result = classifier(text, labels)\n",
    "    \n",
    "    # Check if classification is confident\n",
    "    top_score = result['scores'][0]\n",
    "    confidence_level = \"High\" if top_score > 0.7 else \"Medium\" if top_score > 0.5 else \"Low\"\n",
    "    \n",
    "    print(f\"\\n\\\"{text}\\\"\")\n",
    "    print(f\"  Prediction: {result['labels'][0]} ({top_score:.1%})\")\n",
    "    print(f\"  Confidence: {confidence_level}\")\n",
    "    if confidence_level == \"Low\":\n",
    "        print(f\"  âš ï¸ Warning: Low confidence - consider manual review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-42",
   "metadata": {},
   "source": [
    "### Limitations of Zero-Shot Classification\n",
    "\n",
    "| Limitation | Description | Mitigation |\n",
    "|------------|-------------|------------|\n",
    "| **Accuracy** | May be less accurate than fine-tuned models | Use for prototyping, fine-tune for production |\n",
    "| **Speed** | Slower than traditional classifiers | Batch processing, model optimization |\n",
    "| **Label sensitivity** | Results depend on label phrasing | Test multiple phrasings, use descriptive labels |\n",
    "| **Complex reasoning** | Struggles with nuanced distinctions | Use more specific labels, combine with other methods |\n",
    "| **Domain-specific** | General models may miss domain nuances | Consider domain-specific fine-tuning |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-43",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Label Phrasing Comparison (Independent)\n",
    "\n",
    "**Difficulty**: Advanced | **Time**: 15-20 minutes\n",
    "\n",
    "**Your task**: Build a class that tests different label phrasings and finds the most effective ones.\n",
    "\n",
    "**Requirements**:\n",
    "1. Test multiple phrasings for the same concept\n",
    "2. Compare results across different test texts\n",
    "3. Recommend the best phrasing based on consistency and confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "class LabelOptimizer:\n",
    "    \"\"\"\n",
    "    Tests different label phrasings to find the most effective ones.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.classifier = pipeline(\"zero-shot-classification\")\n",
    "    \n",
    "    def compare_phrasings(self, test_texts, label_variations, expected_labels=None):\n",
    "        \"\"\"\n",
    "        Compare different label phrasings across test texts.\n",
    "        \n",
    "        Args:\n",
    "            test_texts: List of texts to classify\n",
    "            label_variations: Dict of {concept: [phrasing1, phrasing2, ...]}\n",
    "            expected_labels: Optional dict of {text: expected_concept}\n",
    "            \n",
    "        Returns:\n",
    "            Comparison results with recommendations\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # Test each phrasing\n",
    "        for concept, phrasings in label_variations.items():\n",
    "            for phrasing in phrasings:\n",
    "                phrasing_results = {\n",
    "                    'concept': concept,\n",
    "                    'phrasing': phrasing,\n",
    "                    'scores': [],\n",
    "                    'correct': 0,\n",
    "                    'total': 0,\n",
    "                }\n",
    "                \n",
    "                # All phrasings as labels (one from each concept)\n",
    "                all_labels = [phrasings[0] for phrasings in label_variations.values()]\n",
    "                # Replace with current phrasing being tested\n",
    "                concept_idx = list(label_variations.keys()).index(concept)\n",
    "                all_labels[concept_idx] = phrasing\n",
    "                \n",
    "                for text in test_texts:\n",
    "                    result = self.classifier(text, all_labels)\n",
    "                    # Find score for our phrasing\n",
    "                    score_idx = result['labels'].index(phrasing)\n",
    "                    score = result['scores'][score_idx]\n",
    "                    phrasing_results['scores'].append(score)\n",
    "                    \n",
    "                    # Check accuracy if expected labels provided\n",
    "                    if expected_labels and text in expected_labels:\n",
    "                        phrasing_results['total'] += 1\n",
    "                        if expected_labels[text] == concept and result['labels'][0] == phrasing:\n",
    "                            phrasing_results['correct'] += 1\n",
    "                \n",
    "                # Calculate statistics\n",
    "                phrasing_results['avg_score'] = sum(phrasing_results['scores']) / len(phrasing_results['scores'])\n",
    "                phrasing_results['consistency'] = 1 - (max(phrasing_results['scores']) - min(phrasing_results['scores']))\n",
    "                \n",
    "                results.append(phrasing_results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_recommendations(self, comparison_results):\n",
    "        \"\"\"\n",
    "        Recommend the best phrasing for each concept.\n",
    "        \"\"\"\n",
    "        recommendations = {}\n",
    "        \n",
    "        # Group by concept\n",
    "        concepts = set(r['concept'] for r in comparison_results)\n",
    "        \n",
    "        for concept in concepts:\n",
    "            concept_results = [r for r in comparison_results if r['concept'] == concept]\n",
    "            # Sort by average score (higher is better)\n",
    "            best = max(concept_results, key=lambda x: x['avg_score'])\n",
    "            recommendations[concept] = {\n",
    "                'best_phrasing': best['phrasing'],\n",
    "                'avg_score': best['avg_score'],\n",
    "                'consistency': best['consistency'],\n",
    "            }\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = LabelOptimizer()\n",
    "\n",
    "# Test texts\n",
    "test_texts = [\n",
    "    \"This product exceeded my expectations! Highly recommend.\",\n",
    "    \"Terrible experience. The item broke after one day.\",\n",
    "    \"It works fine. Nothing special but gets the job done.\",\n",
    "    \"Absolutely love it! Best purchase I've made this year.\",\n",
    "    \"Very disappointed. Would not buy again.\",\n",
    "]\n",
    "\n",
    "# Different phrasings for the same concepts\n",
    "label_variations = {\n",
    "    'positive': [\"positive\", \"satisfied\", \"happy customer\", \"positive review\"],\n",
    "    'negative': [\"negative\", \"dissatisfied\", \"unhappy customer\", \"negative review\"],\n",
    "    'neutral': [\"neutral\", \"mixed feelings\", \"average opinion\", \"neutral review\"],\n",
    "}\n",
    "\n",
    "# Expected labels for accuracy checking\n",
    "expected = {\n",
    "    \"This product exceeded my expectations! Highly recommend.\": \"positive\",\n",
    "    \"Terrible experience. The item broke after one day.\": \"negative\",\n",
    "    \"It works fine. Nothing special but gets the job done.\": \"neutral\",\n",
    "    \"Absolutely love it! Best purchase I've made this year.\": \"positive\",\n",
    "    \"Very disappointed. Would not buy again.\": \"negative\",\n",
    "}\n",
    "\n",
    "print(\"Testing label phrasings...\")\n",
    "results = optimizer.compare_phrasings(test_texts, label_variations, expected)\n",
    "recommendations = optimizer.get_recommendations(results)\n",
    "\n",
    "print(\"\\nLabel Phrasing Recommendations:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for concept, rec in recommendations.items():\n",
    "    print(f\"\\n[{concept.upper()}]\")\n",
    "    print(f\"  Best phrasing: \\\"{rec['best_phrasing']}\\\"\")\n",
    "    print(f\"  Average score: {rec['avg_score']:.1%}\")\n",
    "    print(f\"  Consistency: {rec['consistency']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed comparison for one concept\n",
    "print(\"\\nDetailed Comparison for 'positive' concept:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "positive_results = [r for r in results if r['concept'] == 'positive']\n",
    "positive_results.sort(key=lambda x: x['avg_score'], reverse=True)\n",
    "\n",
    "for r in positive_results:\n",
    "    bar = '*' * int(r['avg_score'] * 40)\n",
    "    print(f\"  \\\"{r['phrasing']:20s}\\\" avg: {r['avg_score']:6.1%} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-46",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Mini-Project\n",
    "\n",
    "## Project: Custom Content Tagger\n",
    "\n",
    "**Scenario**: You're building a social media management tool that automatically tags posts with relevant categories for organization and analytics.\n",
    "\n",
    "**Your goal**: Build a `CustomContentTagger` class that:\n",
    "1. Supports user-defined tag categories\n",
    "2. Handles multi-label tagging\n",
    "3. Provides confidence scores and filtering\n",
    "4. Suggests hashtags based on classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINI-PROJECT: Custom Content Tagger\n",
    "# ====================================\n",
    "\n",
    "class CustomContentTagger:\n",
    "    \"\"\"\n",
    "    Automatically tags social media content with user-defined categories.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Default category presets\n",
    "    PRESETS = {\n",
    "        'social_media': {\n",
    "            'categories': [\n",
    "                'lifestyle', 'food', 'travel', 'fitness', 'fashion',\n",
    "                'technology', 'business', 'education', 'entertainment', 'news'\n",
    "            ],\n",
    "            'hashtag_map': {\n",
    "                'lifestyle': ['#lifestyle', '#dailylife', '#life'],\n",
    "                'food': ['#foodie', '#food', '#yummy'],\n",
    "                'travel': ['#travel', '#wanderlust', '#explore'],\n",
    "                'fitness': ['#fitness', '#workout', '#health'],\n",
    "                'fashion': ['#fashion', '#style', '#ootd'],\n",
    "                'technology': ['#tech', '#innovation', '#digital'],\n",
    "                'business': ['#business', '#entrepreneur', '#success'],\n",
    "                'education': ['#learning', '#education', '#knowledge'],\n",
    "                'entertainment': ['#entertainment', '#fun', '#music'],\n",
    "                'news': ['#news', '#breaking', '#current'],\n",
    "            }\n",
    "        },\n",
    "        'customer_support': {\n",
    "            'categories': [\n",
    "                'complaint', 'question', 'feedback', 'compliment',\n",
    "                'bug report', 'feature request', 'billing issue'\n",
    "            ],\n",
    "            'priority_map': {\n",
    "                'complaint': 'high',\n",
    "                'bug report': 'high',\n",
    "                'billing issue': 'high',\n",
    "                'question': 'medium',\n",
    "                'feature request': 'low',\n",
    "                'feedback': 'low',\n",
    "                'compliment': 'low',\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def __init__(self, preset='social_media', custom_categories=None):\n",
    "        \"\"\"\n",
    "        Initialize the content tagger.\n",
    "        \n",
    "        Args:\n",
    "            preset: Use a preset configuration ('social_media', 'customer_support')\n",
    "            custom_categories: Override with custom categories\n",
    "        \"\"\"\n",
    "        self.classifier = pipeline(\"zero-shot-classification\")\n",
    "        \n",
    "        if custom_categories:\n",
    "            self.categories = custom_categories\n",
    "            self.preset_config = None\n",
    "        elif preset in self.PRESETS:\n",
    "            self.categories = self.PRESETS[preset]['categories']\n",
    "            self.preset_config = self.PRESETS[preset]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown preset: {preset}\")\n",
    "    \n",
    "    def tag(self, content, threshold=0.3, max_tags=3, multi_label=True):\n",
    "        \"\"\"\n",
    "        Tag content with relevant categories.\n",
    "        \n",
    "        Args:\n",
    "            content: The text content to tag\n",
    "            threshold: Minimum confidence for a tag\n",
    "            max_tags: Maximum number of tags to assign\n",
    "            multi_label: Allow multiple tags\n",
    "            \n",
    "        Returns:\n",
    "            TagResult with tags, scores, and suggestions\n",
    "        \"\"\"\n",
    "        result = self.classifier(\n",
    "            content, \n",
    "            self.categories, \n",
    "            multi_label=multi_label\n",
    "        )\n",
    "        \n",
    "        # Filter and limit tags\n",
    "        selected_tags = []\n",
    "        for label, score in zip(result['labels'], result['scores']):\n",
    "            if score >= threshold and len(selected_tags) < max_tags:\n",
    "                selected_tags.append({'tag': label, 'confidence': score})\n",
    "        \n",
    "        # Generate hashtag suggestions if available\n",
    "        hashtags = []\n",
    "        if self.preset_config and 'hashtag_map' in self.preset_config:\n",
    "            for tag_info in selected_tags:\n",
    "                if tag_info['tag'] in self.preset_config['hashtag_map']:\n",
    "                    hashtags.extend(self.preset_config['hashtag_map'][tag_info['tag']][:2])\n",
    "        \n",
    "        # Get priority if available\n",
    "        priority = None\n",
    "        if self.preset_config and 'priority_map' in self.preset_config:\n",
    "            for tag_info in selected_tags:\n",
    "                if tag_info['tag'] in self.preset_config['priority_map']:\n",
    "                    tag_priority = self.preset_config['priority_map'][tag_info['tag']]\n",
    "                    if priority is None or \\\n",
    "                       (['low', 'medium', 'high'].index(tag_priority) > \n",
    "                        ['low', 'medium', 'high'].index(priority or 'low')):\n",
    "                        priority = tag_priority\n",
    "        \n",
    "        return {\n",
    "            'content_preview': content[:100] + '...' if len(content) > 100 else content,\n",
    "            'tags': selected_tags,\n",
    "            'hashtags': list(set(hashtags))[:5],\n",
    "            'priority': priority,\n",
    "            'all_scores': dict(zip(result['labels'], result['scores'])),\n",
    "        }\n",
    "    \n",
    "    def batch_tag(self, contents, **kwargs):\n",
    "        \"\"\"\n",
    "        Tag multiple pieces of content.\n",
    "        \"\"\"\n",
    "        return [self.tag(content, **kwargs) for content in contents]\n",
    "    \n",
    "    def format_result(self, result):\n",
    "        \"\"\"\n",
    "        Format a tag result for display.\n",
    "        \"\"\"\n",
    "        lines = []\n",
    "        lines.append(f\"Content: \\\"{result['content_preview']}\\\"\")\n",
    "        lines.append(\"\")\n",
    "        lines.append(\"Tags:\")\n",
    "        for tag_info in result['tags']:\n",
    "            lines.append(f\"  - {tag_info['tag']} ({tag_info['confidence']:.1%})\")\n",
    "        \n",
    "        if result['hashtags']:\n",
    "            lines.append(\"\")\n",
    "            lines.append(f\"Suggested Hashtags: {' '.join(result['hashtags'])}\")\n",
    "        \n",
    "        if result['priority']:\n",
    "            lines.append(f\"Priority: {result['priority'].upper()}\")\n",
    "        \n",
    "        return '\\n'.join(lines)\n",
    "\n",
    "\n",
    "# Create a social media tagger\n",
    "tagger = CustomContentTagger(preset='social_media')\n",
    "\n",
    "print(\"Custom Content Tagger - Social Media Mode\")\n",
    "print(f\"Categories: {tagger.categories}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with social media posts\n",
    "posts = [\n",
    "    \"Just got back from an amazing week in Bali! The beaches were incredible and the food was even better. Highly recommend the local warung restaurants! ðŸŒ´ðŸœ\",\n",
    "    \n",
    "    \"Completed my first marathon today! 26.2 miles of pure determination. Training for 6 months was worth every early morning run. ðŸƒâ€â™€ï¸ðŸ’ª\",\n",
    "    \n",
    "    \"Excited to announce that our startup just closed a $5M Series A! Thanks to our incredible team and investors who believed in our vision. ðŸš€\",\n",
    "    \n",
    "    \"New recipe alert! Made the most delicious vegan pasta with homemade cashew cream sauce. Simple ingredients, amazing taste. Recipe in comments! ðŸ\",\n",
    "]\n",
    "\n",
    "print(\"\\nTagging Social Media Posts:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for post in posts:\n",
    "    result = tagger.tag(post, threshold=0.25, max_tags=3)\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(tagger.format_result(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try customer support mode\n",
    "support_tagger = CustomContentTagger(preset='customer_support')\n",
    "\n",
    "support_messages = [\n",
    "    \"I've been charged twice for my subscription this month. Please fix this immediately.\",\n",
    "    \n",
    "    \"The app keeps crashing whenever I try to upload photos. Using iPhone 14 with latest iOS.\",\n",
    "    \n",
    "    \"Would be great if you could add dark mode to the app. It would make late night browsing much easier!\",\n",
    "    \n",
    "    \"Your customer service team was incredibly helpful! Shoutout to Sarah who resolved my issue in minutes.\",\n",
    "]\n",
    "\n",
    "print(\"Customer Support Message Classification:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for message in support_messages:\n",
    "    result = support_tagger.tag(message, threshold=0.3, max_tags=2)\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(support_tagger.format_result(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with custom categories\n",
    "custom_tagger = CustomContentTagger(\n",
    "    custom_categories=[\n",
    "        \"product review\",\n",
    "        \"how-to tutorial\",\n",
    "        \"personal story\",\n",
    "        \"promotional content\",\n",
    "        \"opinion piece\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "custom_content = [\n",
    "    \"After using this laptop for 3 months, here's my honest opinion: the battery life is incredible but the keyboard could be better.\",\n",
    "    \n",
    "    \"Step 1: Open the settings menu. Step 2: Click on Privacy. Step 3: Toggle off location services.\",\n",
    "    \n",
    "    \"Limited time offer! Use code SAVE50 for 50% off all products. Don't miss out!\",\n",
    "]\n",
    "\n",
    "print(\"Custom Category Classification:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for content in custom_content:\n",
    "    result = custom_tagger.tag(content, threshold=0.3)\n",
    "    print(f\"\\n\\\"{content[:70]}...\\\"\")\n",
    "    for tag_info in result['tags']:\n",
    "        print(f\"  â†’ {tag_info['tag']} ({tag_info['confidence']:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own content and categories\n",
    "# Uncomment and modify:\n",
    "\n",
    "# my_tagger = CustomContentTagger(custom_categories=[\"your\", \"categories\", \"here\"])\n",
    "# my_result = my_tagger.tag(\"Your content here\")\n",
    "# print(my_tagger.format_result(my_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-52",
   "metadata": {},
   "source": [
    "### Extension Ideas\n",
    "\n",
    "If you want to extend this project further:\n",
    "\n",
    "1. **Sentiment overlay**: Add sentiment analysis to each tagged post\n",
    "2. **Trending detection**: Track tag frequency over time to identify trends\n",
    "3. **Auto-routing**: Route content to different teams based on tags\n",
    "4. **Custom templates**: Allow users to specify hypothesis templates\n",
    "5. **Hierarchical tagging**: Support parent/child category relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-53",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: Wrap-Up\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Zero-shot classification** lets you classify text without task-specific training\n",
    "\n",
    "2. **NLI-based approach** converts classification into entailment testing:\n",
    "   - Text becomes the premise\n",
    "   - Labels become hypotheses\n",
    "   - Highest entailment score wins\n",
    "\n",
    "3. **Label design matters**:\n",
    "   - Use specific, descriptive labels\n",
    "   - Avoid overlapping categories\n",
    "   - Test multiple phrasings\n",
    "\n",
    "4. **Multi-label mode** (`multi_label=True`):\n",
    "   - Scores each label independently\n",
    "   - Use when categories can overlap\n",
    "   - Set appropriate thresholds\n",
    "\n",
    "5. **Hypothesis templates** can improve accuracy for specific domains\n",
    "\n",
    "## Common Mistakes to Avoid\n",
    "\n",
    "| Mistake | Why It's a Problem |\n",
    "|---------|-------------------|\n",
    "| Vague labels like \"good\" or \"bad\" | Model can't distinguish effectively |\n",
    "| Too many overlapping categories | Scores become unreliable |\n",
    "| Ignoring confidence scores | Low-confidence predictions may be wrong |\n",
    "| Using single-label for overlapping concepts | Misses valid secondary categories |\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "In **Notebook 7: Translation**, you'll learn:\n",
    "- How encoder-decoder models handle translation\n",
    "- Working with multiple language pairs\n",
    "- Evaluating translation quality\n",
    "\n",
    "Translation uses similar encoder-decoder architecture to summarization but for cross-lingual tasks!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solutions\n",
    "\n",
    "### Check Your Understanding (Quiz Answers)\n",
    "\n",
    "1. **B) Because it needs zero task-specific training examples** - You don't need labeled data for your specific task\n",
    "2. **B) Entailment** - The model checks if the text \"entails\" (implies) each label\n",
    "3. **B) To convert labels into testable sentences** - Labels become hypotheses for NLI testing\n",
    "4. **A) Classifying text into categories you just invented** - This is the power of zero-shot classification\n",
    "\n",
    "### Exercise 2: Multi-Label Tagging (Key Insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insights from multi-label tagging:\n",
    "\n",
    "# 1. Use multi_label=True when:\n",
    "#    - Categories can overlap (e.g., \"tech\" AND \"business\")\n",
    "#    - You want to assign multiple tags\n",
    "#    - Content can belong to several categories\n",
    "\n",
    "# 2. Set appropriate thresholds:\n",
    "#    - 0.5+ for high confidence only\n",
    "#    - 0.3-0.5 for balanced coverage\n",
    "#    - 0.2-0.3 for broad tagging\n",
    "\n",
    "# 3. Limit max_tags to avoid noise:\n",
    "#    - 3-5 tags usually sufficient\n",
    "#    - Too many tags reduce signal\n",
    "\n",
    "threshold_guide = {\n",
    "    'strict': {'threshold': 0.6, 'use_case': 'High-stakes classification'},\n",
    "    'balanced': {'threshold': 0.4, 'use_case': 'General content tagging'},\n",
    "    'broad': {'threshold': 0.25, 'use_case': 'Exploratory tagging, suggestions'},\n",
    "}\n",
    "\n",
    "print(\"Threshold Selection Guide:\")\n",
    "print(\"=\"*60)\n",
    "for level, config in threshold_guide.items():\n",
    "    print(f\"  {level:10s}: threshold={config['threshold']} - {config['use_case']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-56",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [Hugging Face Zero-Shot Classification](https://huggingface.co/tasks/zero-shot-classification)\n",
    "- [BART Paper](https://arxiv.org/abs/1910.13461) - Base model for many zero-shot classifiers\n",
    "- [Natural Language Inference Explained](https://nlp.stanford.edu/projects/snli/) - Stanford NLI dataset\n",
    "- [Zero-Shot Text Classification Blog](https://joeddav.github.io/blog/2020/05/29/ZSL.html) - In-depth tutorial\n",
    "- [Multi-NLI Dataset](https://cims.nyu.edu/~sbowman/multinli/) - Training data for NLI models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
